#!/usr/bin/env python3
"""Encode tasks as embeddings."""
import rospy
from semantic_inference_msgs.msg import FeatureVectors
from semantic_inference_msgs.srv import EncodeFeature


class TaskServer:
    """Server to compute and distribute task embeddings."""

    def __init__(self):
        """Get embeddings for tasks."""
        self._object_pub = rospy.Publisher(
            "~objects", FeatureVectors, queue_size=1, latch=True
        )
        self._place_pub = rospy.Publisher(
            "~places", FeatureVectors, queue_size=1, latch=True
        )

        object_tasks = rospy.get_param("~object_tasks", [])
        if len(object_tasks) > 0:
            msg = self._embed_tasks(object_tasks)
            self._object_pub.publish(msg)

        place_tasks = rospy.get_param("~place_tasks", [])
        if len(place_tasks) > 0:
            msg = self._embed_tasks(place_tasks)
            self._place_pub.publish(msg)

    def _embed_tasks(self, tasks, service_name="semantic_inference/embed"):
        rospy.loginfo(f"[{rospy.get_name()}] Waiting for {service_name}")
        rospy.wait_for_service(service_name)
        proxy = rospy.ServiceProxy(service_name, EncodeFeature)
        rospy.loginfo(f"[{rospy.get_name()}] Encoding features for {tasks}")

        msg = FeatureVectors()
        for task in tasks:
            msg.names.append(task)
            msg.features.append(proxy(task).feature.feature)

        rospy.loginfo(f"[{rospy.get_name()}] Finished encoding features!")
        return msg

    def spin(self):
        """Wait for ros to shutdown."""
        rospy.spin()


def main():
    """Start the task server."""
    rospy.init_node("task_server")
    server = TaskServer()
    server.spin()


if __name__ == "__main__":
    main()
